{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard libraries for data handling and visualization\n",
        "import seaborn as sns  # Visualization\n",
        "import matplotlib.pyplot as plt  # Plotting\n",
        "import numpy as np  # Numerical operations\n",
        "import os, glob, random  # File handling and randomness\n",
        "import pandas as pd  # Tabular data processing\n",
        "\n",
        "# TensorFlow and Keras for deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint  # To save model checkpoints during training\n",
        "from keras.saving import register_keras_serializable  # To register custom components\n",
        "\n",
        "# Check available GPU devices\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Hyperparameters and Data Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32  # Batch size for training\n",
        "\n",
        "target_shape = (224, 224) # Target image size (height, width)\n",
        "\n",
        "IMG_SHAPE = target_shape + (3,)  # The full shape of input images\n",
        "\n",
        "# Path to the image dataset (update this as needed for your environment).\n",
        "pathData = r'./Samples'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing Data for Siamese Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This class is responsible for managing the dataset directory structure and splitting it into training, validation, and test sets.\n",
        "\n",
        "class subset_manager:\n",
        "\n",
        "    def __init__(self, datasetPath, selectedImgs=20, split_ratio=(0.75, 0.2, 0.05)):\n",
        "        \"\"\"\n",
        "        Initialize the subset manager.\n",
        "\n",
        "        Args:\n",
        "            datasetPath (str): Path to the dataset where each subfolder represents a class or identity.\n",
        "            selectedImgs (int): Minimum number of images required to include a folder in the dataset.\n",
        "            split_ratio (tuple): Train/validation/test split ratio.\n",
        "        \"\"\"\n",
        "        self.sampleNames = list()  # List to store valid sample folder paths\n",
        "        self.selectedImgs = selectedImgs  # Minimum image count threshold\n",
        "        self.split_ratio = split_ratio  # Proportions for splitting\n",
        "\n",
        "        # Iterate through each subdirectory (i.e., identity or class folder)\n",
        "        for folderName in os.listdir(datasetPath):\n",
        "            absoluteFolderName = os.path.join(datasetPath, folderName)\n",
        "            numImages = len(os.listdir(absoluteFolderName))\n",
        "\n",
        "            # Include only those folders with more than `selectedImgs` images\n",
        "            if numImages > self.selectedImgs:\n",
        "                self.sampleNames.append(absoluteFolderName)\n",
        "\n",
        "        # Shuffle the sample list to ensure randomness in splitting\n",
        "        random.shuffle(self.sampleNames)\n",
        "\n",
        "\n",
        "    def get_split_folders(self):\n",
        "        \"\"\"\n",
        "        Splits the collected sample folders into train, validation, and test sets.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Lists of folder paths for train, validation, and test splits.\n",
        "        \"\"\"\n",
        "        n_total = len(self.sampleNames)\n",
        "        n_train = round(self.split_ratio[0] * n_total)\n",
        "        n_val = round(self.split_ratio[1] * n_total)\n",
        "\n",
        "        # Slice the shuffled list to create train/val/test splits\n",
        "        train_folders = self.sampleNames[:n_train]\n",
        "        val_folders = self.sampleNames[n_train:n_train + n_val]\n",
        "        test_folders = self.sampleNames[n_train + n_val:]\n",
        "\n",
        "        # Print the distribution of the dataset\n",
        "        print(f\"Train instance: {len(train_folders)} \\nValidation instance: {len(val_folders)} \\nTest instance: {len(test_folders)}\")\n",
        "\n",
        "        return train_folders, val_folders, test_folders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This class is used to read image files from disk, decode, resize, and normalize them for use in the Siamese Network.\n",
        "\n",
        "class MapFunction():\n",
        "\n",
        "    def __init__(self, imageSize):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            imageSize (tuple): Target size to which all images will be resized (height, width).\n",
        "        \"\"\"\n",
        "        self.imageSize = imageSize\n",
        "\n",
        "    def decode_and_resize(self, imagePath):\n",
        "        \"\"\"\n",
        "        Reads an image from disk, decodes it from JPEG, normalizes pixel values to [0,1],\n",
        "        and resizes it to the target image size.\n",
        "\n",
        "        Args:\n",
        "            imagePath (tf.Tensor): File path to the image.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Preprocessed image tensor.\n",
        "        \"\"\"\n",
        "        image = tf.io.read_file(imagePath)  # Load raw image from path\n",
        "        image = tf.image.decode_jpeg(image, channels=3)  # Decode JPEG to tensor\n",
        "        image = tf.image.convert_image_dtype(image, dtype=tf.float32)  # Normalize to [0,1]\n",
        "        image = tf.image.resize(image, self.imageSize)  # Resize to target shape\n",
        "\n",
        "        return image\n",
        "\n",
        "    def __call__(self, anchor, positive, negative):\n",
        "        \"\"\"\n",
        "        Applies preprocessing to the anchor, positive, and negative images.\n",
        "\n",
        "        Args:\n",
        "            anchor (str): File path of anchor image.\n",
        "            positive (str): File path of positive image (same class as anchor).\n",
        "            negative (str): File path of negative image (different class from anchor).\n",
        "\n",
        "        Returns:\n",
        "            Tuple: ((anchor_tensor, positive_tensor, negative_tensor), dummy_label)\n",
        "        \"\"\"\n",
        "        anchor = self.decode_and_resize(anchor)\n",
        "        positive = self.decode_and_resize(positive)\n",
        "        negative = self.decode_and_resize(negative)\n",
        "\n",
        "        return (anchor, positive, negative), 0.0  # Output dummy label (needed for Keras training)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TripletGenerator: Class to Dynamically Generate Triplets for Siamese Network Training\n",
        "# This class loads images from folders and generates anchor, positive, and negative triplet samples for training.\n",
        "\n",
        "class TripletGenerator:\n",
        "\n",
        "    def __init__(self, datasetPath, selectedImgs=20, mode='Train'):\n",
        "        \"\"\"\n",
        "        Initialize the triplet generator.\n",
        "\n",
        "        Args:\n",
        "            datasetPath (list): List of folder paths, where each folder contains images of one identity.\n",
        "            selectedImgs (int): Number of images to sample per identity.\n",
        "            mode (str): String label to indicate whether this is 'Train', 'Validation', or 'Test' mode.\n",
        "        \"\"\"\n",
        "        self.idsNames = list()  # List to store folders (identities) with sufficient images\n",
        "        self.allImages = 0  # Counter for total number of images used\n",
        "        self.selectedImgs = selectedImgs\n",
        "        self.mode = mode\n",
        "\n",
        "        # Filter folders with at least `selectedImgs` images\n",
        "        for absoluteFolderName in datasetPath:\n",
        "            numImages = len(os.listdir(absoluteFolderName))\n",
        "            if numImages > self.selectedImgs:\n",
        "                self.idsNames.append(absoluteFolderName)\n",
        "\n",
        "        # Generate dictionary mapping each identity to its selected image paths\n",
        "        self.allIds = self.generate_all_ids_dict()\n",
        "\n",
        "        # Print summary\n",
        "        self.__str__()\n",
        "\n",
        "    def count_number_images(self):\n",
        "        \"\"\"Returns the total number of images used across all identities.\"\"\"\n",
        "        return self.allImages\n",
        "\n",
        "    def count_number_samples(self):\n",
        "        \"\"\"Returns the number of identities used.\"\"\"\n",
        "        return len(self.allIds)\n",
        "\n",
        "    def generate_all_ids_dict(self):\n",
        "        \"\"\"\n",
        "        Creates a dictionary where keys are identity folder paths and values are lists of selected image paths.\n",
        "\n",
        "        Returns:\n",
        "            dict: Mapping from identity name to list of selected image paths.\n",
        "        \"\"\"\n",
        "        allIds = dict()\n",
        "\n",
        "        for idName in self.idsNames:\n",
        "            imageNames = os.listdir(idName)\n",
        "            idPhotos = [os.path.join(idName, imageName) for imageName in imageNames]\n",
        "            self.allImages += len(idPhotos)\n",
        "            idPhotos = self.get_random_sample(idPhotos)  # Sample a fixed number of images per ID\n",
        "            allIds[idName] = idPhotos\n",
        "\n",
        "        return allIds\n",
        "\n",
        "    def get_random_sample(self, imgs):\n",
        "        \"\"\"\n",
        "        Uniformly selects `self.selectedImgs` samples from the list of images.\n",
        "\n",
        "        Args:\n",
        "            imgs (list): List of image paths.\n",
        "\n",
        "        Returns:\n",
        "            list: Sampled image paths.\n",
        "        \"\"\"\n",
        "        indices = np.linspace(0, len(imgs) - 1, self.selectedImgs, dtype=int)\n",
        "        return [imgs[i] for i in indices]  # Alternative: random.sample(imgs, self.selectedImgs)\n",
        "\n",
        "    def get_next_element(self):\n",
        "        \"\"\"\n",
        "        Generator function that continuously yields triplets (anchor, positive, negative).\n",
        "\n",
        "        Yields:\n",
        "            tuple: (anchor_path, positive_path, negative_path)\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            # Choose a random identity for anchor and positive\n",
        "            anchorName = random.choice(self.idsNames)\n",
        "\n",
        "            # Choose a different identity for negative\n",
        "            temporaryNames = self.idsNames.copy()\n",
        "            temporaryNames.remove(anchorName)\n",
        "            negativeName = random.choice(temporaryNames)\n",
        "\n",
        "            # Select two different images from the same identity\n",
        "            (anchorPhoto, positivePhoto) = np.random.choice(\n",
        "                a=self.allIds[anchorName], size=2, replace=False\n",
        "            )\n",
        "\n",
        "            # Select one image from a different identity\n",
        "            negativePhoto = random.choice(self.allIds[negativeName])\n",
        "\n",
        "            yield (anchorPhoto, positivePhoto, negativePhoto)\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Print a summary of the current dataset status.\"\"\"\n",
        "        print(f\"[INFO] {self.mode} Dataset:\")\n",
        "        print(f\"TripletGenerator instance with value: {self.count_number_samples()} \\n\"\n",
        "              f\"and total imgs with value: {self.count_number_images()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and Split the Dataset Using subset_manager\n",
        "\n",
        "# Initialize the subset manager with the root dataset path\n",
        "subset = subset_manager(pathData)\n",
        "\n",
        "# Split the dataset folders into training, validation, and test sets\n",
        "train_folders, val_folders, test_folders = subset.get_split_folders()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build tf.data Pipeline for Training\n",
        "\n",
        "# Initialize the TripletGenerator with the training folders\n",
        "TrainGenerator = TripletGenerator(train_folders)\n",
        "\n",
        "# Create a tf.data.Dataset from the generator that yields (anchor, positive, negative) image paths\n",
        "TfDatasetTrain = tf.data.Dataset.from_generator(\n",
        "    generator=TrainGenerator.get_next_element,  # Custom generator yielding image path triplets\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),  # Anchor path\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),  # Positive path\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),  # Negative path\n",
        "    )\n",
        ")\n",
        "\n",
        "# Number of triplets to use per epoch (controls how many samples are taken from the generator)\n",
        "k = 20000\n",
        "\n",
        "# Create a MapFunction instance to decode and preprocess images\n",
        "mapFunctionTrain = MapFunction(imageSize=target_shape)\n",
        "\n",
        "# Map preprocessing function to the dataset\n",
        "train_dataset = TfDatasetTrain.map(mapFunctionTrain, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Final data pipeline:\n",
        "# - Take `k` triplets\n",
        "# - Cache for performance\n",
        "# - Shuffle for randomness\n",
        "# - Batch for training\n",
        "# - Prefetch for optimized GPU utilization\n",
        "train_dataset = (\n",
        "    train_dataset\n",
        "    .take(k)\n",
        "    .cache()\n",
        "    .shuffle(256)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build tf.data Pipeline for Validation\n",
        "\n",
        "# Initialize the TripletGenerator with validation folders\n",
        "ValGenerator = TripletGenerator(val_folders, mode='Validation')\n",
        "\n",
        "# Create a tf.data.Dataset from the generator that yields validation triplets\n",
        "TfDatasetVal = tf.data.Dataset.from_generator(\n",
        "    generator=ValGenerator.get_next_element,  # Custom generator yielding triplets\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),  # Anchor path\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),  # Positive path\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),  # Negative path\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a MapFunction instance for preprocessing validation images\n",
        "mapFunctionVal = MapFunction(imageSize=target_shape)\n",
        "\n",
        "# Map the preprocessing function to the dataset\n",
        "val_dataset = TfDatasetVal.map(mapFunctionVal, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Final validation dataset pipeline:\n",
        "# - Take the same number of triplets as training (k)\n",
        "# - Cache for performance\n",
        "# - No shuffle (important for consistent evaluation)\n",
        "# - Batch for model input\n",
        "# - Prefetch for efficient data loading\n",
        "val_dataset = (\n",
        "    val_dataset\n",
        "    .take(k)\n",
        "    .cache()\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def visualize(anchor_batch, positive_batch, negative_batch, num_triplets=3):\n",
        "    \"\"\"\n",
        "    Visualize a few triplets from the supplied batches.\n",
        "\n",
        "    Parameters:\n",
        "      anchor_batch, positive_batch, negative_batch: batches of images,\n",
        "          each of shape (batch_size, H, W, C)\n",
        "      num_triplets: how many triplets to show\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axs = plt.subplots(num_triplets, 3, figsize=(9, 3 * num_triplets))\n",
        "\n",
        "    def show(ax, image, title=None):\n",
        "        ax.imshow(image)\n",
        "        ax.axis('off')\n",
        "        if title:\n",
        "            ax.set_title(title)\n",
        "\n",
        "    for i in range(num_triplets):\n",
        "        show(axs[i, 0], anchor_batch[i], 'Anchor' if i == 0 else None)\n",
        "        show(axs[i, 1], positive_batch[i], 'Positive' if i == 0 else None)\n",
        "        show(axs[i, 2], negative_batch[i], 'Negative' if i == 0 else None)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Usage example:\n",
        "for batch in train_dataset.take(1):\n",
        "    inputs, targets = batch\n",
        "    anchor_batch, positive_batch, negative_batch = inputs  # inputs is a tuple/list of 3 batches\n",
        "    visualize(anchor_batch, positive_batch, negative_batch, num_triplets=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Definition & Training with Distributed Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup for Distributed Training\n",
        "\n",
        "# Create a MirroredStrategy to distribute the model across multiple GPUs\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Print the number of replicas (i.e., GPUs) being used\n",
        "print(\"Number of devices: \", strategy.num_replicas_in_sync)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom Triplet Margin Loss Function\n",
        "# This loss encourages the network to place the anchor closer to the positive than to the negative by at least a margin.\n",
        "\n",
        "@register_keras_serializable()  # Makes the custom loss serializable for model saving/loading\n",
        "class TripletMarginLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, margin=0.5,\n",
        "                 reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
        "                 name=\"triplet_margin_loss\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            margin (float): Minimum distance by which a negative sample should be farther than a positive one.\n",
        "            reduction (str): How to reduce loss across batches.\n",
        "            name (str): Name for the loss function.\n",
        "        \"\"\"\n",
        "        super().__init__(reduction=reduction, name=name)\n",
        "        self.margin = margin\n",
        "\n",
        "    def call(self, _, y_pred):\n",
        "        \"\"\"\n",
        "        Computes the triplet margin loss.\n",
        "\n",
        "        Args:\n",
        "            _ (unused): Ground truth labels (not needed for triplet loss).\n",
        "            y_pred (tf.Tensor): Predicted distances of shape (batch_size, 2),\n",
        "                                where [:,0] is anchor-positive and [:,1] is anchor-negative.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Scalar loss value.\n",
        "        \"\"\"\n",
        "        ap_distance = y_pred[:, 0]  # Distance between anchor and positive\n",
        "        an_distance = y_pred[:, 1]  # Distance between anchor and negative\n",
        "\n",
        "        # Loss = max(ap - an + margin, 0)\n",
        "        loss = tf.maximum(ap_distance - an_distance + self.margin, 0.0)\n",
        "\n",
        "        return tf.reduce_mean(loss)  # Mean loss over the batch\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Required for Keras serialization.\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"margin\": self.margin\n",
        "        })\n",
        "        return config\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom Distance Layer for Triplet Loss\n",
        "# This layer computes the squared L2 distances between:\n",
        "# - Anchor and Positive embeddings\n",
        "# - Anchor and Negative embeddings\n",
        "\n",
        "class DistanceLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the custom Keras layer.\n",
        "        Inherits from keras.layers.Layer and accepts optional keyword arguments.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, anchor, positive, negative):\n",
        "        \"\"\"\n",
        "        Compute the pairwise distances between anchor-positive and anchor-negative.\n",
        "\n",
        "        Args:\n",
        "            anchor (tf.Tensor): Embedding vector for the anchor.\n",
        "            positive (tf.Tensor): Embedding vector for the positive sample.\n",
        "            negative (tf.Tensor): Embedding vector for the negative sample.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: A stacked tensor of shape (batch_size, 2) with\n",
        "                       [AP_distance, AN_distance] for each triplet.\n",
        "        \"\"\"\n",
        "        # Squared L2 distance between anchor and positive\n",
        "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
        "\n",
        "        # Squared L2 distance between anchor and negative\n",
        "        an_distance = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
        "\n",
        "        # Stack the distances into a single tensor for use in loss computation\n",
        "        return tf.stack([ap_distance, an_distance], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom layer to perform L2 normalization\n",
        "\n",
        "class L2Normalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, axis=1, **kwargs):\n",
        "        \"\"\"\n",
        "        Custom layer to perform L2 normalization on inputs along a specified axis.\n",
        "\n",
        "        Args:\n",
        "            axis (int): The axis along which to perform normalization. Default is 1.\n",
        "            **kwargs: Additional keyword arguments for Layer superclass.\n",
        "        \"\"\"\n",
        "        super(L2Normalization, self).__init__(**kwargs)\n",
        "        self.axis = axis  # Store the axis to normalize along\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward pass: apply L2 normalization to the input tensor.\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): Input tensor to normalize.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: L2-normalized tensor along the specified axis.\n",
        "        \"\"\"\n",
        "        return tf.math.l2_normalize(inputs, axis=self.axis)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the config of the layer, useful for saving/loading the model.\n",
        "\n",
        "        Returns:\n",
        "            dict: Configuration dictionary with the axis parameter included.\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config.update({\"axis\": self.axis})\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(checkpoint_filepath, FineTuningMode=False):\n",
        "    \"\"\"\n",
        "    Creates and returns a Siamese network model using ResNet50 as the backbone.\n",
        "\n",
        "    Args:\n",
        "        checkpoint_filepath (str): Path to load model weights if fine-tuning.\n",
        "        FineTuningMode (bool): If True, enables partial fine-tuning of ResNet50.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: A Siamese network model that outputs anchor-positive and anchor-negative distances.\n",
        "\n",
        "    Why normalize embeddings before computing distance?\n",
        "    - Normalization (e.g., L2 normalization) projects embeddings onto the unit hypersphere.\n",
        "    - This makes Euclidean distance equivalent to cosine similarity in terms of ranking.\n",
        "    - It improves stability and convergence of training.\n",
        "    - Prevents embeddings from growing arbitrarily large, stabilizing triplet loss.\n",
        "    \"\"\"\n",
        "\n",
        "    base_cnn = tf.keras.applications.ResNet50(\n",
        "        weights=\"imagenet\", input_shape=IMG_SHAPE, include_top=False\n",
        "    )\n",
        "\n",
        "    if FineTuningMode:\n",
        "        trainable = False\n",
        "        for layer in base_cnn.layers:\n",
        "            if layer.name == \"conv5_block2_out\":\n",
        "                trainable = True\n",
        "            layer.trainable = trainable\n",
        "    else:\n",
        "        base_cnn.trainable = False\n",
        "\n",
        "    flatten = tf.keras.layers.Flatten()(base_cnn.output)\n",
        "    dense1 = tf.keras.layers.Dense(512, activation=\"relu\")(flatten)\n",
        "    dense1 = tf.keras.layers.BatchNormalization()(dense1)\n",
        "\n",
        "    dense2 = tf.keras.layers.Dense(256, activation=\"relu\")(flatten)\n",
        "    dense2 = tf.keras.layers.BatchNormalization()(dense2)\n",
        "\n",
        "    output = tf.keras.layers.Dense(128)(dense1)\n",
        "    output = L2Normalization(axis=1)(output)\n",
        "\n",
        "    embedding = tf.keras.Model(base_cnn.input, output, name=\"Embedding\")\n",
        "\n",
        "    anchor_input = tf.keras.layers.Input(name=\"anchor\", shape=target_shape + (3,))\n",
        "    positive_input = tf.keras.layers.Input(name=\"positive\", shape=target_shape + (3,))\n",
        "    negative_input = tf.keras.layers.Input(name=\"negative\", shape=target_shape + (3,))\n",
        "\n",
        "    distances = DistanceLayer()(\n",
        "        embedding(tf.keras.applications.resnet.preprocess_input(anchor_input)),\n",
        "        embedding(tf.keras.applications.resnet.preprocess_input(positive_input)),\n",
        "        embedding(tf.keras.applications.resnet.preprocess_input(negative_input)),\n",
        "    )\n",
        "\n",
        "    siamese_network = tf.keras.Model(\n",
        "        inputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
        "    )\n",
        "\n",
        "    if FineTuningMode:\n",
        "        siamese_network.load_weights(checkpoint_filepath)\n",
        "\n",
        "    return siamese_network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path to save/load model weights (checkpoint) - (update this as needed for your environment)\n",
        "checkpoint_filepath = r'./Siamese.keras'\n",
        "\n",
        "# Training schedule parameters\n",
        "initial_epochs = 10          # Number of epochs for initial training (frozen backbone)\n",
        "fine_tune_epochs = 190       # Number of epochs for fine-tuning (unfreeze backbone)\n",
        "total_epochs = initial_epochs + fine_tune_epochs  # Total epochs to train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build and compile the Siamese network inside the distribution strategy scope\n",
        "with strategy.scope():\n",
        "    # Create the model, passing the checkpoint path (freeze mode assumed here)\n",
        "    siamese_network = create_model(checkpoint_filepath=checkpoint_filepath, FineTuningMode=False)\n",
        "\n",
        "    # Compile the model with Adam optimizer and custom Triplet Margin Loss\n",
        "    siamese_network.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=TripletMarginLoss()\n",
        "    )\n",
        "\n",
        "    # Instantiate optimizer separately if needed later (e.g., for fine-tuning)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ModelCheckpoint callback to save the best model during training\n",
        "\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,       # Where to save the model file\n",
        "    monitor='val_loss',                 # Metric to monitor\n",
        "    save_best_only=True,                # Save only when val_loss improves\n",
        "    save_weights_only=False,            # Save full model (architecture + weights)\n",
        "    mode='min',                        # 'val_loss' should be minimized\n",
        "    verbose=1                         # Show messages when saving\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training Phase 1: Train with Frozen Base Model\n",
        "\n",
        "# In this phase, the backbone (ResNet50) layers are frozen (non-trainable),\n",
        "# so only the newly added dense layers and batch norm layers get updated.\n",
        "# This helps the model stabilize initial embedding learning without\n",
        "# disturbing pretrained feature extraction.\n",
        "\n",
        "history = siamese_network.fit(\n",
        "    train_dataset,           # Training data (triplet batches)\n",
        "    validation_data=val_dataset,  # Validation data for monitoring\n",
        "    epochs=initial_epochs,   # Train for the initial number of epochs (frozen backbone)\n",
        "    callbacks=[checkpoint_cb]  # Save best model based on validation loss\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training and validation loss over epochs to monitor performance\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 1.0])  # Limit y-axis for better visualization\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tuning phase: Unfreeze part of the base model and continue training\n",
        "\n",
        "with strategy.scope():\n",
        "    # Create model with fine-tuning enabled (unfreeze last ResNet blocks)\n",
        "    siamese_network = create_model(checkpoint_filepath=checkpoint_filepath, FineTuningMode=True)\n",
        "\n",
        "    # Compile with optimizer and custom triplet margin loss\n",
        "    siamese_network.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=TripletMarginLoss()\n",
        "    )\n",
        "\n",
        "    # Keep an optimizer instance if needed later (optional)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tuning training: Continue training the model with unfrozen layers\n",
        "\n",
        "history_fine = siamese_network.fit(\n",
        "    train_dataset,           # Training data (triplets)\n",
        "    validation_data=val_dataset,  # Validation data for monitoring\n",
        "    epochs=total_epochs,     # Total epochs including initial + fine-tuning\n",
        "    callbacks=[checkpoint_cb]  # Save the best model checkpoint during fine-tuning\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine loss history from initial training and fine-tuning phases\n",
        "\n",
        "loss += history_fine.history['loss']\n",
        "val_loss += history_fine.history['val_loss']\n",
        "\n",
        "# Find the epoch with the lowest validation loss (best model)\n",
        "BestWeights = val_loss.index(min(val_loss))\n",
        "\n",
        "print(f\"[INFO] the siamese network training results:\")\n",
        "print(f'Saved Best Weights at epoch {BestWeights}.')\n",
        "print(f'Training loss at best epoch: {loss[BestWeights]:.4f}')\n",
        "print(f'Validation loss at best epoch: {val_loss[BestWeights]:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot combined training and validation loss with markers for key events\n",
        "\n",
        "plt.subplot(2, 1, 2)  # Use second subplot if plotting multiple figures above\n",
        "\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.ylim([0, 1.1])\n",
        "plt.xlim([1, BestWeights + 2])  # Focus x-axis around the best epoch\n",
        "\n",
        "# Set x-axis ticks every 10 epochs\n",
        "plt.xticks(np.arange(0, total_epochs + 1, 10))\n",
        "\n",
        "# Vertical line marking start of fine-tuning phase\n",
        "plt.axvline(x=initial_epochs, color='orange', linestyle='--', label='Start Fine Tuning')\n",
        "\n",
        "# Vertical line marking epoch with best validation loss\n",
        "plt.axvline(x=BestWeights, color='blue', linestyle='--', label='Save Best Weights')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save training and validation loss history to an Excel file for later analysis\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['Train'] = loss           # Training loss per epoch\n",
        "df['Validation'] = val_loss  # Validation loss per epoch\n",
        "\n",
        "df.to_excel('Loss.xlsx', index=False)  # Export DataFrame to 'Loss.xlsx' without row indices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation of the Trained Model\n",
        "\n",
        "## Test Set Evaluation Logic\n",
        "\n",
        "- For each identity (ID), **select 21 images** evenly spaced from the available images.\n",
        "- From these 21 images, **choose the first image as the \"indicator\"** embedding representing that ID.\n",
        "- The remaining 20 images are used as **test samples** for that ID.\n",
        "- Extract embeddings for all indicators and test samples using the trained embedding model.\n",
        "- For each indicator:\n",
        "  - Calculate distances to its own test samples (**anchor-positive distances**).\n",
        "  - Calculate distances to test samples from **all other IDs** (**anchor-negative distances**).\n",
        "- Using these distances, build a **confusion matrix** that reflects how often the model correctly matches the anchor to its positives versus negatives.\n",
        "- This setup simulates the triplet structure used during training:\n",
        "  - **Anchor** = indicator embedding\n",
        "  - **Positive** = test sample from the same ID\n",
        "  - **Negative** = test sample from a different ID\n",
        "- The confusion matrix and distance comparisons help evaluate how well the model separates different classes based on the embeddings.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the best saved weights into the Siamese network model before evaluation\n",
        "siamese_network.load_weights(checkpoint_filepath)\n",
        "\n",
        "\n",
        "# Extract the embedding sub-model (named 'Embedding') from the trained Siamese network\n",
        "for layer in siamese_network.layers:\n",
        "    if layer.name == 'Embedding':\n",
        "        trainedEmbedding = layer\n",
        "        break  # Optional: stop once found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model to a file named \"embedding_model.keras\"\n",
        "# This saves the entire model architecture, weights, and optimizer state (if any).\n",
        "trainedEmbedding.save(\"./embedding_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the saved model from disk.\n",
        "# Because the model includes a custom layer (L2Normalization),\n",
        "# we need to provide it in the `custom_objects` dictionary\n",
        "# so Keras knows how to reconstruct that layer when loading.\n",
        "trainedEmbedding = tf.keras.models.load_model(\n",
        "    \"./embedding_model.keras\",\n",
        "    custom_objects={\"L2Normalization\": L2Normalization}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare and extract embeddings for the test set samples\n",
        "\n",
        "def decode_and_resize(imagePath, imageSize):\n",
        "    # Read image from disk, decode JPEG, convert to float32, and resize to target shape\n",
        "    image = tf.io.read_file(imagePath)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    image = tf.image.resize(image, imageSize)\n",
        "    return image\n",
        "\n",
        "TestSamples, indSamples = [], []\n",
        "\n",
        "for folder in test_folders:\n",
        "    # Collect image file paths and shuffle them\n",
        "    imgs = glob.glob(os.path.join(folder, '*.jpg'))\n",
        "    random.shuffle(imgs)\n",
        "\n",
        "    # Select 21 evenly spaced images from the folder\n",
        "    indices = np.linspace(0, len(imgs)-1, 21, dtype=int)\n",
        "    imgs = [imgs[i] for i in indices]\n",
        "\n",
        "    allImgs = []\n",
        "    for img_path in imgs:\n",
        "        img = decode_and_resize(img_path, target_shape)\n",
        "        allImgs.append(img)\n",
        "\n",
        "    # Convert list to numpy array and preprocess for ResNet\n",
        "    allImgs = np.array(allImgs)\n",
        "    allImgs = tf.keras.applications.resnet.preprocess_input(allImgs)\n",
        "\n",
        "    # Get embeddings from the trained embedding model\n",
        "    features = trainedEmbedding(allImgs)\n",
        "\n",
        "    # First embedding as indicator, rest as test samples\n",
        "    indSamples.append(features[0])\n",
        "    TestSamples.append(features[1:])\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "indSamples = np.array(indSamples)\n",
        "TestSamples = np.array(TestSamples)\n",
        "\n",
        "print(f'Indicators shape: {indSamples.shape} and Test Samples shape: {TestSamples.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate a confusion matrix based on triplet distances between embeddings\n",
        "\n",
        "confusionMatrix = []\n",
        "\n",
        "for i in range(indSamples.shape[0]):\n",
        "    ind = indSamples[i]               # Anchor indicator embedding for class i\n",
        "    samples = TestSamples[i, ...]     # Positive samples embeddings for class i\n",
        "\n",
        "    # Compute anchor-positive distances (within same class)\n",
        "    ap_distance = tf.reduce_sum(tf.square(ind - samples), axis=-1).numpy()\n",
        "\n",
        "    # Initialize confusion vector for class i with zeros\n",
        "    confusionVector = [0] * indSamples.shape[0]\n",
        "\n",
        "    for j in range(indSamples.shape[0]):\n",
        "        if j == i:\n",
        "            continue  # Skip same class comparison\n",
        "\n",
        "        # Negative samples embeddings from class j\n",
        "        samples_neg = TestSamples[j, ...]\n",
        "\n",
        "        # Compute anchor-negative distances (between classes)\n",
        "        an_distance = tf.reduce_sum(tf.square(ind - samples_neg), axis=-1).numpy()\n",
        "\n",
        "        # Stack distances for comparison: shape (2, number_of_samples)\n",
        "        pair = np.array([ap_distance, an_distance])\n",
        "\n",
        "        # Find which distance is smaller for each sample (0: ap_distance, 1: an_distance)\n",
        "        min_indices = tf.argmin(pair, axis=0)\n",
        "\n",
        "        # Count how many times negative distance is smaller (hard negatives)\n",
        "        count = int(tf.reduce_sum(min_indices).numpy())\n",
        "\n",
        "        # Update confusion vector counts\n",
        "        confusionVector[i] += min_indices.shape[0] - count  # Correct matches (AP smaller)\n",
        "        confusionVector[j] = count                          # Confused with class j (AN smaller)\n",
        "\n",
        "    confusionMatrix.append(confusionVector)\n",
        "\n",
        "confusionMatrix = np.array(confusionMatrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assessing Model Accuracy and Metrics\n",
        "\n",
        "Confusion Matrix Visualization\n",
        "\n",
        "This function plots the confusion matrix as a heatmap using Seaborn, where:\n",
        "\n",
        "- The x-axis corresponds to predicted classes.\n",
        "- The y-axis corresponds to true classes.\n",
        "- Cell values represent the number of samples classified from true class (row) to predicted class (column).\n",
        "- Color intensity helps quickly identify where the model performs well or struggles.\n",
        "\n",
        "Use this to visually inspect the model's classification performance across different identities.\n",
        "\n",
        "---\n",
        "\n",
        "Per-Class Evaluation Metrics Calculation\n",
        "\n",
        "For each class, we compute the following metrics using the confusion matrix:\n",
        "\n",
        "- **True Positives (TP):** Correctly predicted samples of this class.\n",
        "- **False Positives (FP):** Samples incorrectly predicted as this class.\n",
        "- **False Negatives (FN):** Samples of this class incorrectly predicted as others.\n",
        "- **True Negatives (TN):** Samples correctly predicted as not belonging to this class.\n",
        "\n",
        "From these, we calculate:\n",
        "\n",
        "- **Accuracy:** Overall correctness of predictions.\n",
        "- **Precision:** How many predicted positives are actually correct.\n",
        "- **Sensitivity (Recall):** How many actual positives were correctly identified.\n",
        "- **Specificity:** How many actual negatives were correctly identified.\n",
        "- **Approximate AUC:** Average of sensitivity and specificity to estimate the Area Under the Curve.\n",
        "\n",
        "These metrics help understand the model's performance on each individual class.\n",
        "\n",
        "---\n",
        "\n",
        "Adding Average Metrics Row\n",
        "\n",
        "- After calculating per-class metrics, we compute the average of each metric across all classes.\n",
        "- This average row is appended to the results matrix to provide an overall summary.\n",
        "- The `class_names` list is updated accordingly to label this summary row as \"Average per class\".\n",
        "\n",
        "---\n",
        "\n",
        "Visualization of Per-Class Performance Metrics\n",
        "\n",
        "- The heatmap displays the evaluation metrics (Accuracy, Precision, Sensitivity, Specificity, AUC) for each class.\n",
        "- Scores are shown in percentage form for better readability.\n",
        "- The color intensity indicates higher or lower metric values, providing a quick visual assessment.\n",
        "- The last row corresponds to the average metrics across all classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_confusion_matrix(cm, labels):\n",
        "    \"\"\"\n",
        "    Display a confusion matrix as a heatmap using Seaborn.\n",
        "\n",
        "    Args:\n",
        "        cm (np.array): Confusion matrix (2D array).\n",
        "        labels (list): List of label names for the axes.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    sns.heatmap(cm, xticklabels=labels, yticklabels=labels,\n",
        "                annot=True, fmt='g', cmap='Greens')\n",
        "    plt.xlabel('Prediction')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Confusion Matrix Heatmap')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create class names based on the number of identities in the confusion matrix\n",
        "class_names = [f'S{i}' for i in range(confusionMatrix.shape[0])]\n",
        "\n",
        "# Visualize the confusion matrix using the class names as labels\n",
        "show_confusion_matrix(confusionMatrix, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_matrix = []\n",
        "num_class = confusionMatrix.shape[0]\n",
        "\n",
        "for i in range(num_class):\n",
        "    # True Positives: correctly predicted samples for class i\n",
        "    n_tp = confusionMatrix[i][i]\n",
        "\n",
        "    # False Positives: samples predicted as class i but belonging to other classes\n",
        "    n_fp = sum([confusionMatrix[i][j] for j in range(num_class)]) - n_tp\n",
        "\n",
        "    # False Negatives: samples belonging to class i but predicted as other classes\n",
        "    n_fn = sum([confusionMatrix[j][i] for j in range(num_class)]) - n_tp\n",
        "\n",
        "    # True Negatives: samples neither predicted as class i nor belonging to class i\n",
        "    n_tn = confusionMatrix.sum() - n_tp - n_fp - n_fn\n",
        "\n",
        "    # Compute evaluation metrics for class i\n",
        "    acc = (n_tp + n_tn) / (n_tp + n_tn + n_fp + n_fn)  # Accuracy\n",
        "    Pr = n_tp / (n_tp + n_fp)                          # Precision\n",
        "    Sen = n_tp / (n_tp + n_fn)                         # Sensitivity / Recall\n",
        "    Spe = n_tn / (n_tn + n_fp)                         # Specificity\n",
        "    AUC = (Sen + Spe) / 2                              # Approximate AUC\n",
        "\n",
        "    result_matrix.append([acc, Pr, Sen, Spe, AUC])\n",
        "\n",
        "result_matrix = np.asarray(result_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add label for the average metrics row\n",
        "class_names.append('Average per class')\n",
        "\n",
        "# Calculate average metrics across all classes\n",
        "average = result_matrix.sum(axis=0) / num_class\n",
        "\n",
        "# Expand dims to make average compatible for appending as a new row\n",
        "average = np.expand_dims(average, axis=0)\n",
        "\n",
        "# Append the average metrics as a new row to the result matrix\n",
        "result_matrix = np.append(result_matrix, average, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_names = ['Accuracy', 'Precision', 'Sensitivity', 'Specificity', 'AUC']\n",
        "\n",
        "# Plot per-class evaluation metrics as a heatmap\n",
        "plt.figure(figsize=(12, 14))\n",
        "sns.heatmap(result_matrix * 100, annot=True, fmt=\".2f\", cmap=\"Greens\",\n",
        "            xticklabels=metrics_names, yticklabels=class_names,\n",
        "            linewidths=0.5, cbar_kws={'label': 'Score (%)'})\n",
        "plt.title(\"Per-Class Performance Metrics\")\n",
        "plt.xlabel(\"Metrics\")\n",
        "plt.ylabel(\"Classes\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "siamese_network",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python Pro6",
      "language": "python",
      "name": "pro6"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
